V dynamic learning rate 
	start with 0.01 if acc doesn't improve 5 epochs learn/=2; if learn < (bound = 0.0001): learn = bound
V different opt
	adam
	rmsprop
	adagrad

V hidden units 
	try 300 like static rnn project
V bach size
	tried 100, 200, 300
V change emb file
V multi cell
V enlarge data file
V initializer=tf.contrib.layers.xavier_initializer()

V get different loss funcs
try lr again

attention https://programtalk.com/python-examples/tensorflow.contrib.rnn.AttentionCellWrapper/
truncated back propofation through time https://www.tensorflow.org/tutorials/sequences/recurrent#truncated_backpropagation



